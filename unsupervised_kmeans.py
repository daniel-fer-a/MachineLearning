# -*- coding: utf-8 -*-
"""unsupervised_kmeans

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iPVr2DUb21r74sswB24N8Vx3jWeVpaH0
"""


# === CONFIGURACIÓN ===

import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

PATH_APPLICATION_TRAIN = "application_.parquet"
TARGET_COL = "TARGET"


# === CARGA DE DATOS ===

print("Cargando dataset...")
df = pd.read_parquet(PATH_APPLICATION_TRAIN)
print("Shape:", df.shape)
print("Columnas:", len(df.columns))

y = df[TARGET_COL]

possible_pd_cols = [
    c for c in df.columns
    if c.lower().startswith(("pd_", "score_", "proba_", "prob_"))
]
PD_COL = possible_pd_cols[0] if len(possible_pd_cols) else None
print("Columna PD detectada:", PD_COL)


# === VARIABLES ===

numeric_features = [
    "AMT_INCOME_TOTAL",
    "AMT_CREDIT",
    "AMT_ANNUITY",
    "AMT_GOODS_PRICE",
    "CNT_CHILDREN",
    "CNT_FAM_MEMBERS",
    "DAYS_BIRTH",
    "DAYS_EMPLOYED",
    "DAYS_REGISTRATION",
    "DAYS_ID_PUBLISH",
    "DAYS_LAST_PHONE_CHANGE",
    "REGION_POPULATION_RELATIVE",
    "EXT_SOURCE_1",
    "EXT_SOURCE_2",
    "EXT_SOURCE_3",
]

categorical_features = [
    "NAME_CONTRACT_TYPE",
    "CODE_GENDER",
    "FLAG_OWN_CAR",
    "FLAG_OWN_REALTY",
    "NAME_INCOME_TYPE",
    "NAME_EDUCATION_TYPE",
    "NAME_FAMILY_STATUS",
    "NAME_HOUSING_TYPE",
    "OCCUPATION_TYPE",
    "ORGANIZATION_TYPE",
]

numeric_features = [c for c in numeric_features if c in df.columns]
categorical_features = [c for c in categorical_features if c in df.columns]

print("Vars numéricas:", numeric_features)
print("Vars categóricas:", categorical_features)

X = df[numeric_features + categorical_features].copy()


# === PREPROCESAMIENTO ===

numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features),
    ]
)


# === BÚSQUEDA DE K ===

print("\nBuscando mejor K...")
k_values = [2, 3, 4, 5, 6, 7, 8]
results = []

for k in k_values:
    model_k = Pipeline(steps=[
        ("preprocess", preprocessor),
        ("cluster", KMeans(n_clusters=k, random_state=42, n_init=10))
    ])
    model_k.fit(X)
    inertia = model_k.named_steps["cluster"].inertia_
    Xt = model_k.named_steps["preprocess"].transform(X)
    labels = model_k.named_steps["cluster"].labels_
    sil = silhouette_score(Xt, labels)
    results.append({"k": k, "inertia": inertia, "silhouette": sil})
    print(f"K={k} | inertia={inertia:.2f} | silhouette={sil:.4f}")

results_df = pd.DataFrame(results)
results_df.to_csv("kmeans_k_search_results.csv", index=False)

best_row = results_df.loc[results_df["silhouette"].idxmax()]
K_FINAL = int(best_row["k"])
print("\nK seleccionado:", K_FINAL)


# === MODELO FINAL ===

print("\nEntrenando modelo final...")
final_model = Pipeline(steps=[
    ("preprocess", preprocessor),
    ("cluster", KMeans(n_clusters=K_FINAL, random_state=42, n_init=10))
])

final_model.fit(X)
df["CLUSTER_KMEANS"] = final_model.named_steps["cluster"].labels_

print("\nDistribución de clusters:")
print(df["CLUSTER_KMEANS"].value_counts())


# === RESUMEN POR CLUSTER ===

grouped = df.groupby("CLUSTER_KMEANS")

cluster_summary = grouped.agg(
    n_clientes=("CLUSTER_KMEANS", "count"),
    tasa_mora=(TARGET_COL, "mean"),
)

if PD_COL is not None:
    cluster_summary["pd_media"] = grouped[PD_COL].mean()

cluster_summary["porcentaje"] = cluster_summary["n_clientes"] / len(df)

print("\nResumen de riesgo por cluster:")
print(cluster_summary)

cluster_summary.to_csv("kmeans_cluster_summary.csv")


# === PERFIL NUMÉRICO ===

profile_numeric = grouped[numeric_features].mean()
profile_numeric.to_csv("kmeans_cluster_profile_numeric.csv")

print("\nPerfil numérico por cluster guardado.")


# === DATASET FINAL ===

out_path = "application_with_clusters.parquet"
df.to_parquet(out_path)

print("\nArchivo final generado:", out_path)
print("\nProceso completado.")
